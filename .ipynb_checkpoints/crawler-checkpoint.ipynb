{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fb7d6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "13734c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7,ar;q=0.6\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "    \"X-S2-Client\": \"webapp-browser\",\n",
    "    \"X-S2-Ui-Version\": \"452cc270c0d8e73927dd44144435f75b41e2c43a\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "658902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_paper(title):\n",
    "    # Define the API endpoint\n",
    "    url = \"https://www.semanticscholar.org/api/1/search\"\n",
    "\n",
    "    # Define the data to be sent in the POST request\n",
    "    data = {\n",
    "        \"queryString\": title,\n",
    "        \"page\": 1,\n",
    "        \"authors\": [],\n",
    "        \"coAuthors\": [],\n",
    "        \"cues\": [\"CitedByLibraryPaperCue\"],\n",
    "        \"fieldsOfStudy\": [],\n",
    "        \"getQuerySuggestions\": False,\n",
    "        \"hydrateWithDdb\": True,\n",
    "        \"includeBadges\": True,\n",
    "        \"includePdfVisibility\": False,\n",
    "        \"includeTldrs\": True,\n",
    "        \"pageSize\": 10,\n",
    "        \"performTitleMatch\": True,\n",
    "        \"requireViewablePdf\": False,\n",
    "        \"sort\": \"relevance\",\n",
    "        \"useFallbackRankerService\": False,\n",
    "        \"useFallbackSearchCluster\": False,\n",
    "        \"venues\": [],\n",
    "        \"yearFilter\": None\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "\n",
    "    response_data = response.json()\n",
    "\n",
    "   # Filter results by title match and find the result with the highest numReferences\n",
    "    max_references = -1\n",
    "    paper_id_with_max_references = None\n",
    "\n",
    "    for result in response_data['results']:\n",
    "        if result['title']['text'] == title:\n",
    "            current_references = result['citationStats']['numReferences'] if 'citationStats' in result else 0\n",
    "            if current_references > max_references:\n",
    "                max_references = current_references\n",
    "                paper_id_with_max_references = result['id']\n",
    "\n",
    "    if paper_id_with_max_references is None:\n",
    "        raise Exception(\"No matching papers found with the specified title.\")\n",
    "\n",
    "    return paper_id_with_max_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38797aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail(seed_id):\n",
    "    # Define the API endpoint\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/{seed_id}\"\n",
    "\n",
    "    # Specify the fields we want in the response\n",
    "    params = {\n",
    "        \"fields\": \"title,venue,year,authors,abstract,citationCount,externalIds,url\"\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "   \n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract required information\n",
    "    result = {\n",
    "        \"paperId\": data[\"paperId\"],\n",
    "        \"title\": data[\"title\"],\n",
    "        \"author\": data[\"authors\"][0][\"name\"] if data[\"authors\"] else None,\n",
    "        \"venue\": data[\"venue\"],\n",
    "        \"year\": data[\"year\"],\n",
    "        \"citationCount\": data[\"citationCount\"],\n",
    "        \"url\": f'https://arxiv.org/abs/{data[\"externalIds\"][\"ArXiv\"]}' if \"ArXiv\" in data[\"externalIds\"] else data[\"url\"],\n",
    "        \"abstract\": data[\"abstract\"]\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "472103e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def write_node_data(data, file_name, fields):\n",
    "    with open(file_name, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "        with open(file_name, 'r', newline='', encoding='utf-8') as readfile:\n",
    "            reader = csv.DictReader(readfile)\n",
    "            if any(row['paperId'] == data['paperId'] for row in reader):\n",
    "                return\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e977d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references(seed_id):\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/{seed_id}/references\"\n",
    "    params = {\n",
    "        \"fields\": \"contexts,intents,isInfluential,paperId,year,abstract\",\n",
    "        \"limit\": \"1000\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "    \n",
    "    data = response.json()['data']\n",
    "    \n",
    "    # year가 2020 이후이고, abstract에 'robot'이 포함되며, isInfluential이 True인 것만 필터링\n",
    "    filtered_data = [entry for entry in data \n",
    "                     if entry['citedPaper']['year'] is not None \n",
    "                     and entry['citedPaper']['year'] >= 2020\n",
    "                     and entry['citedPaper'].get('abstract')\n",
    "                     and 'robot' in entry['citedPaper']['abstract'].lower()\n",
    "                     and entry['isInfluential']]\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ea2c14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "\n",
    "def write_edge_data(data, file_name, fields):                                              \n",
    "    with open(file_name, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a5e01e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# CSV 파일에서 'title' 컬럼의 데이터를 읽어와서 seed_papers 초기화\n",
    "def get_seeds(file_name):\n",
    "    titles = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            titles.append(row['title'])\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3f558600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining seeds: 4\n",
      "Remaining seeds: 3\n",
      "Remaining seeds: 7\n",
      "Remaining seeds: 7\n",
      "Remaining seeds: 8\n",
      "Remaining seeds: 7\n",
      "Remaining seeds: 9\n",
      "Remaining seeds: 8\n",
      "Remaining seeds: 7\n",
      "Remaining seeds: 6\n",
      "Remaining seeds: 6\n",
      "Remaining seeds: 5\n",
      "Remaining seeds: 4\n",
      "Remaining seeds: 3\n",
      "Remaining seeds: 2\n",
      "Remaining seeds: 1\n",
      "Remaining seeds: 1\n",
      "Remaining seeds: 0\n"
     ]
    }
   ],
   "source": [
    "SEED_FILE_NAME = 'seeds.csv'\n",
    "\n",
    "NODE_FILE_NAME = 'papers.csv'\n",
    "NODE_FILE_FIELDS = ['paperId', 'title', 'author', 'venue', 'year', 'citationCount',  'url', 'abstract']\n",
    "\n",
    "EDGE_FILE_NAME = 'references.csv'\n",
    "EDGE_FILE_FIELDS=['from_id', 'to_id', 'isInfluential', 'intents', 'contexts']\n",
    "\n",
    "\n",
    "with open(NODE_FILE_NAME, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=NODE_FILE_FIELDS)\n",
    "    writer.writeheader()\n",
    "\n",
    "with open(EDGE_FILE_NAME, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=EDGE_FILE_FIELDS)\n",
    "    writer.writeheader() \n",
    "\n",
    "seed_ids = []\n",
    "processed_ids = set()  # 이미 처리된 id를 저장할 집합\n",
    "\n",
    "for seed_paper in get_seeds(SEED_FILE_NAME):\n",
    "    seed_id = search_paper(seed_paper)\n",
    "    seed_ids.append(seed_id)\n",
    "    processed_ids.add(seed_id)\n",
    "\n",
    "while seed_ids:    \n",
    "    seed_id = seed_ids.pop(0)\n",
    "    detail = get_detail(seed_id)                                    \n",
    "    write_node_data(detail, NODE_FILE_NAME, NODE_FILE_FIELDS) \n",
    "    \n",
    "    refs = get_references(seed_id)\n",
    "    for ref in refs:\n",
    "        ref_id = ref['citedPaper']['paperId']\n",
    "        # ref의 paperId가 seed_papers에 없고, 처리되지 않은 id인 경우 추가\n",
    "        if ref_id not in seed_papers and ref_id not in processed_ids:\n",
    "            seed_papers.append(ref_id)\n",
    "            seed_ids.append(ref_id)\n",
    "            processed_ids.add(ref_id)\n",
    "\n",
    "        edge_data = {\n",
    "            'from_id': seed_id,\n",
    "            'to_id': ref_id,\n",
    "            'isInfluential': ref['isInfluential'],\n",
    "            'intents': ','.join(ref['intents']),\n",
    "            'contexts': ','.join(ref['contexts'])\n",
    "        }\n",
    "\n",
    "        write_edge_data(edge_data, EDGE_FILE_NAME, EDGE_FILE_FIELDS)\n",
    "        \n",
    "    print(f\"Remaining seeds: {len(seed_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53106128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
